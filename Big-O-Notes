Big-O is the Asymtotic worst case runtime 

Big-O analysis is not a way to formalize what the runtime of an algo will be 
given a specific input size. It is a way to formlize how the number of steps will scale 
according to the input size (the behavior of the line). 

The RAM Model of Computation 
  - RAM stands for Random Access Machine 
  - Lets us analyze algos independent of the hardware / language  
  - We measure the runtime of an algo by counting the number of steps 
  - Case Complexity 
    * Best Case: the function defined by the minimum number of steps taken on any
      instance of size n
    * Average Case: average number of steps taken on any instance of size n
    * Worst Case: maximum number of steps taken on any instance of size n
  - Within the RAMMC the best, average, and worst case are hard to deal with 
    precisely
      * Better to deal with the the upper and lower bounds of function 
        (Asymptotic Notation) 
      * Asymptotic Notation: How we describe the behavior of a line as it approaches
        some arbitrary limit (infinity) 
          + Upper Bound: 
          + Lower Bound:
          + Tight Bound:

